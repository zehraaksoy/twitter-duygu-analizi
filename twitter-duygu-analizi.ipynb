{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30004,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Lojistik Regresyonla Tweet Duygu Analizi\n","metadata":{}},{"cell_type":"markdown","source":"## Kütüphaneler ve Veri","metadata":{}},{"cell_type":"code","source":"import nltk\nfrom os import getcwd","metadata":{"execution":{"iopub.status.busy":"2024-07-23T11:32:47.285285Z","iopub.execute_input":"2024-07-23T11:32:47.285973Z","iopub.status.idle":"2024-07-23T11:32:47.292315Z","shell.execute_reply.started":"2024-07-23T11:32:47.285913Z","shell.execute_reply":"2024-07-23T11:32:47.290926Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"Veri seti olarak NLTK'in [Twitter Samples](http://www.nltk.org/howto/twitter.html) veri setini kullanıyoruz. Stopword'leri de yine NLTK üzerinden indiriyoruz.","metadata":{}},{"cell_type":"code","source":"nltk.download('twitter_samples')","metadata":{"execution":{"iopub.status.busy":"2024-07-23T11:32:47.294412Z","iopub.execute_input":"2024-07-23T11:32:47.294760Z","iopub.status.idle":"2024-07-23T11:33:07.347582Z","shell.execute_reply.started":"2024-07-23T11:32:47.294727Z","shell.execute_reply":"2024-07-23T11:33:07.346483Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"[nltk_data] Error loading twitter_samples: <urlopen error [Errno -3]\n[nltk_data]     Temporary failure in name resolution>\n","output_type":"stream"},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"False"},"metadata":{}}]},{"cell_type":"code","source":"nltk.download('stopwords')","metadata":{"execution":{"iopub.status.busy":"2024-07-23T11:33:07.349242Z","iopub.execute_input":"2024-07-23T11:33:07.349711Z","iopub.status.idle":"2024-07-23T11:33:27.387203Z","shell.execute_reply.started":"2024-07-23T11:33:07.349654Z","shell.execute_reply":"2024-07-23T11:33:27.386084Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"[nltk_data] Error loading stopwords: <urlopen error [Errno -3]\n[nltk_data]     Temporary failure in name resolution>\n","output_type":"stream"},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"False"},"metadata":{}}]},{"cell_type":"markdown","source":"Program üzerinde çalışırken tekrar tekrar veriyi indirmek zorunda kalmamamı için aşağıdaki kod parçasını yazıyoruz.","metadata":{}},{"cell_type":"code","source":"filePath = f\"{getcwd()}/../tmp2/\"\nnltk.data.path.append(filePath)","metadata":{"execution":{"iopub.status.busy":"2024-07-23T11:33:27.390052Z","iopub.execute_input":"2024-07-23T11:33:27.390510Z","iopub.status.idle":"2024-07-23T11:33:27.396088Z","shell.execute_reply.started":"2024-07-23T11:33:27.390470Z","shell.execute_reply":"2024-07-23T11:33:27.394795Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"### Verinin Hazırlanması\n* `twitter_samples` veri seti 5.000 olumlu 5.000 olumsuz olmak üzere 10.000 Tweet verisi içerir.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom nltk.corpus import twitter_samples \nimport re\nimport string\nimport numpy as np\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nfrom nltk.tokenize import TweetTokenizer","metadata":{"execution":{"iopub.status.busy":"2024-07-23T11:33:27.398875Z","iopub.execute_input":"2024-07-23T11:33:27.399279Z","iopub.status.idle":"2024-07-23T11:33:27.411499Z","shell.execute_reply.started":"2024-07-23T11:33:27.399239Z","shell.execute_reply":"2024-07-23T11:33:27.410517Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"\n#### Yardımcı fonksiyonlar:\n* `process_tweet()`: Metni temizler, tokenlara ayırır, stopwordleri kaldırır ve kelimeleri köklerine indirger.","metadata":{}},{"cell_type":"code","source":"def process_tweet(tweet):\n\n    stemmer = PorterStemmer()\n    stopwords_english = stopwords.words('english')\n    \n    # Kelime eklerinin, tag isaretlerinin vs. temizlenmesi \n    tweet = re.sub(r'\\$\\w*', '', tweet) \n    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n    tweet = re.sub(r'#', '', tweet)\n    \n    # Metnin tokenlara(kelimelere) ayrilmasi\n    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True) \n    tweet_tokens = tokenizer.tokenize(tweet)\n    \n    # On islemesi gerceklesmis metnin saklanacagi dizi\n    tweets_clean = []\n    \n    for word in tweet_tokens:\n        # Stopwordlerin kaldirilmasi\n        if (word not in stopwords_english and  \n                word not in string.punctuation):  \n            \n            # Kelimenin kokune indirgenmesi\n            stem_word = stemmer.stem(word) \n            tweets_clean.append(stem_word)\n\n    return tweets_clean\n","metadata":{"execution":{"iopub.status.busy":"2024-07-23T11:33:27.413484Z","iopub.execute_input":"2024-07-23T11:33:27.414220Z","iopub.status.idle":"2024-07-23T11:33:27.427599Z","shell.execute_reply.started":"2024-07-23T11:33:27.414137Z","shell.execute_reply":"2024-07-23T11:33:27.426423Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"* `build_freqs()`: Bu fonksiyon kelimelerin olumlu ve olumsuz cümlelerde kaçar defa geçtiğini sayarak olumlu ve olumsuz cümle frekanslarını belirlememizi sağlar.","metadata":{}},{"cell_type":"code","source":"def build_freqs(tweets, ys):\n    \n    yslist = np.squeeze(ys).tolist()\n    freqs = {}\n    for y, tweet in zip(yslist, tweets):\n        for word in process_tweet(tweet):\n            pair = (word, y)\n            if pair in freqs:\n                freqs[pair] += 1\n            else:\n                freqs[pair] = 1\n\n    return freqs","metadata":{"execution":{"iopub.status.busy":"2024-07-23T11:33:27.429226Z","iopub.execute_input":"2024-07-23T11:33:27.429604Z","iopub.status.idle":"2024-07-23T11:33:27.439120Z","shell.execute_reply.started":"2024-07-23T11:33:27.429568Z","shell.execute_reply":"2024-07-23T11:33:27.437911Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"* Olumlu ve olumsuz tweetlerin 1000'er tanesini testte 4000'er tanesini eğitim sırasında kullanmak için ayırıyoruz.","metadata":{}},{"cell_type":"code","source":"all_positive_tweets = twitter_samples.strings('positive_tweets.json')\nall_negative_tweets = twitter_samples.strings('negative_tweets.json')\n\ntest_pos = all_positive_tweets[4000:]\ntrain_pos = all_positive_tweets[:4000]\ntest_neg = all_negative_tweets[4000:]\ntrain_neg = all_negative_tweets[:4000]\n\ntrain_x = train_pos + train_neg \ntest_x = test_pos + test_neg","metadata":{"execution":{"iopub.status.busy":"2024-07-23T11:33:27.440758Z","iopub.execute_input":"2024-07-23T11:33:27.441104Z","iopub.status.idle":"2024-07-23T11:33:28.554491Z","shell.execute_reply.started":"2024-07-23T11:33:27.441070Z","shell.execute_reply":"2024-07-23T11:33:28.553517Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"* Olumlu tweetleri 1, olumsuz tweetleri 0 olarak işaretliyoruz.","metadata":{}},{"cell_type":"code","source":"train_y = np.append(np.ones((len(train_pos), 1)), np.zeros((len(train_neg), 1)), axis=0)\ntest_y = np.append(np.ones((len(test_pos), 1)), np.zeros((len(test_neg), 1)), axis=0)","metadata":{"execution":{"iopub.status.busy":"2024-07-23T11:33:28.555983Z","iopub.execute_input":"2024-07-23T11:33:28.556346Z","iopub.status.idle":"2024-07-23T11:33:28.564645Z","shell.execute_reply.started":"2024-07-23T11:33:28.556314Z","shell.execute_reply":"2024-07-23T11:33:28.563582Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"* Frekansları bir matriste tutalım.","metadata":{}},{"cell_type":"code","source":"freqs = build_freqs(train_x, train_y)\nprint(\"type(freqs) = \" + str(type(freqs)))\nprint(\"len(freqs) = \" + str(len(freqs.keys())))","metadata":{"execution":{"iopub.status.busy":"2024-07-23T11:33:28.566709Z","iopub.execute_input":"2024-07-23T11:33:28.567213Z","iopub.status.idle":"2024-07-23T11:33:33.744507Z","shell.execute_reply.started":"2024-07-23T11:33:28.567134Z","shell.execute_reply":"2024-07-23T11:33:33.743333Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"type(freqs) = <class 'dict'>\nlen(freqs) = 11346\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Tweet işleme\nTweetlerin ilk halini ve ön işleme uygulandıktan sonra algoritmaya sokacağımız halini inceleyelim.","metadata":{}},{"cell_type":"code","source":"print('Pozitif bir tweet: \\n', train_x[0])\nprint('\\nAynı tweetin işlenmiş hali: \\n', process_tweet(train_x[0]))","metadata":{"execution":{"iopub.status.busy":"2024-07-23T11:33:33.745939Z","iopub.execute_input":"2024-07-23T11:33:33.746338Z","iopub.status.idle":"2024-07-23T11:33:33.754223Z","shell.execute_reply.started":"2024-07-23T11:33:33.746303Z","shell.execute_reply":"2024-07-23T11:33:33.753139Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Pozitif bir tweet: \n #FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)\n\nAynı tweetin işlenmiş hali: \n ['followfriday', 'top', 'engag', 'member', 'commun', 'week', ':)']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Lojistik Regresyon\n\n\n### Sigmoid Fonksiyonu\nSigmoid fonksiyonu ikili sınıflandırmalarda kullanılır.\n* Matematiksel olarak sigmoid fonksiyonu:\n\n$$ h(z) = \\frac{1}{1+\\exp^{-z}} \\tag{1}$$\n\nBu fonksiyon almış olduğu inputa(z) 0 ila 1 arasında bir değer atar. 0.5'in altındaki değerler bir sınıfa 0.5'in üstündeki değerler diğer sınıfa dahil olur.\n\n\n<div style=\"width:image width px; font-size:100%; text-align:center;\"><img src='https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/1200px-Logistic-curve.svg.png' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"width:300px;height:200px;\" /></div>","metadata":{}},{"cell_type":"markdown","source":"Sigmoid fonksiyonunun kodunu yazalım.","metadata":{}},{"cell_type":"code","source":"def sigmoid(z):     \n    h = 1/(1+np.exp(-z))\n    return h","metadata":{"execution":{"iopub.status.busy":"2024-07-23T11:33:33.755707Z","iopub.execute_input":"2024-07-23T11:33:33.756039Z","iopub.status.idle":"2024-07-23T11:33:33.767609Z","shell.execute_reply.started":"2024-07-23T11:33:33.756007Z","shell.execute_reply":"2024-07-23T11:33:33.766578Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"Sigmoid fonksiyonundan beklediğimiz sonuçları alabiliyor muyuz diye test edelim.","metadata":{}},{"cell_type":"code","source":"if (sigmoid(0) == 0.5):\n    print('Doğru sonuç!')\nelse:\n    print('Hata!')\n\nif (sigmoid(4.92) == 0.9927537604041685):\n    print('Harika!')\nelse:\n    print('Hata!')","metadata":{"execution":{"iopub.status.busy":"2024-07-23T11:33:33.769415Z","iopub.execute_input":"2024-07-23T11:33:33.769782Z","iopub.status.idle":"2024-07-23T11:33:33.780755Z","shell.execute_reply.started":"2024-07-23T11:33:33.769744Z","shell.execute_reply":"2024-07-23T11:33:33.779788Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"Doğru sonuç!\nHarika!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Lojistik Regresyon ve Sigmoid Fonksiyonu\n\nLojistik regresyon lineer regresyonun çıktısına sigmoid fonksiyonu uygular ve böylece ikili sınıflandırma yapma imkanı verir.\n\nLineer Regresyon:\n$$z = \\theta_0 x_0 + \\theta_1 x_1 + \\theta_2 x_2 + ... \\theta_N x_N$$\n\nLojistik Regresyon\n$$ h(z) = \\frac{1}{1+\\exp^{-z}}$$\n\n$$z = \\theta_0 x_0 + \\theta_1 x_1 + \\theta_2 x_2 + ... \\theta_N x_N$$\n\n\n<div style=\"width:image width px; font-size:100%; text-align:center;\"><img src='https://miro.medium.com/v2/resize:fit:2000/1*zFM1ajUSh2r_sG8dQGkkeA.gif' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"width:300px;height:200px;\" /></div>\n","metadata":{}},{"cell_type":"markdown","source":"### Maliyet Fonksiyonu ve Gradyan Hesabı\n\nLojistik regresyonda maliyet hesabı için log loss fonksiyonunu kullanıyoruz:\n\n$$J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^m y^{(i)}\\log (h(z(\\theta)^{(i)})) + (1-y^{(i)})\\log (1-h(z(\\theta)^{(i)}))\\tag{5} $$\n* $m$  eğitim verisi sayısı\n* $y^{(i)}$  i. eğitim verisinin gerçek değeri\n* $h(z(\\theta)^{(i)})$ modelin i. eğitim verisi için tahmini \n\nTek bir eğitim için maliyet fonksiyonu:\n$$ Loss = -1 \\times \\left( y^{(i)}\\log (h(z(\\theta)^{(i)})) + (1-y^{(i)})\\log (1-h(z(\\theta)^{(i)})) \\right)$$\n\n* Model 1 tahmin ettiğinde ($h(z(\\theta)) = 1$) ve $y$'de 1 olduğunda, maliyet fonksiyonu 0 üretecek yani hiç kayıp olmayacaktır. \n* Benzer şekilde, model 0 tahmin edip ($h(z(\\theta)) = 0$) gerçek değer de 0 olduğu durumlarda da, maliyet fonksiyonu 0 üretecektir. \n* Ancak, model 1'e yakın bir değer tahmin edip ($h(z(\\theta)) = 0.9999$) gerçek değer 0 olduğu durumlarda, maliyet fonksiyonu büyük bir değer alacaktır $-1 \\times (1 - 0) \\times log(1 - 0.9999) \\approx 9.2$. \n* Tahmin değeri 0'a yaklaştıkça maliyet fonksiyonunun değeri de küçülecektir.","metadata":{}},{"cell_type":"code","source":"# dogru sonuc aldigimizi teyit edelim\n-1 * (1 - 0) * np.log(1 - 0.9999) ","metadata":{"execution":{"iopub.status.busy":"2024-07-23T11:33:33.782494Z","iopub.execute_input":"2024-07-23T11:33:33.783014Z","iopub.status.idle":"2024-07-23T11:33:33.793890Z","shell.execute_reply.started":"2024-07-23T11:33:33.782910Z","shell.execute_reply":"2024-07-23T11:33:33.792615Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"9.210340371976294"},"metadata":{}}]},{"cell_type":"code","source":"-1 * np.log(0.0001) ","metadata":{"execution":{"iopub.status.busy":"2024-07-23T11:33:33.795602Z","iopub.execute_input":"2024-07-23T11:33:33.796023Z","iopub.status.idle":"2024-07-23T11:33:33.806476Z","shell.execute_reply.started":"2024-07-23T11:33:33.795984Z","shell.execute_reply":"2024-07-23T11:33:33.805277Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"9.210340371976182"},"metadata":{}}]},{"cell_type":"markdown","source":"#### Ağırlıkları güncelleyelim\n\nAğırlık vektörünü($\\theta$) güncellemek için, gradient descent(dereceli azalma) algoritmasını iteratif olarak uygulayıp parametrelerin optimum seviyeye yaklaşmasını sağlayalım.\nMaliyet fonksiyonunun($J$) ağırlıklardan birine göre ($\\theta_j$) türevi:\n\n$$\\nabla_{\\theta_j}J(\\theta) = \\frac{1}{m} \\sum_{i=1}^m(h^{(i)}-y^{(i)})x_j \\tag{5}$$\n* 'i' parametresi 'm' adet eğitimden kaçıncı eğitimde olduğumuz bilgisini tutuyor \n\n* 'j' ağırlıkların($\\theta_j$) indeksini tutuyor, $x_j$ ise $\\theta_j$ ağırlığının feature bilgisini bulunduruyor.\n\n* $\\theta_j$'yı güncellemek için $\\alpha$'ya göre türevinin bir kısmını çıkarıyoruz:\n$$\\theta_j = \\theta_j - \\alpha \\times \\nabla_{\\theta_j}J(\\theta) $$\n\n* Öğrenme derecesi($\\alpha$), her güncellemenin ne kadar büyük etki edeceğini belirleyen bir parametredir.","metadata":{}},{"cell_type":"markdown","source":"## Gradient descent fonksiyonunun uygulanması\n* `num_iters`: iterasyon sayısı \n* Her iterasyonda tek bir ağırlığı($\\theta_i$) güncellemek yerine aynı anda tüm ağırlıkları bir vektör olarak güncelleyebiliriz:\n\n$$\\mathbf{\\theta} = \\begin{pmatrix}\n\\theta_0\n\\\\\n\\theta_1\n\\\\ \n\\theta_2 \n\\\\ \n\\vdots\n\\\\ \n\\theta_n\n\\end{pmatrix}$$\n\n* $\\mathbf{\\theta}$, (n+1, 1) boyutlarında bir vektördür. 'n' feature sayısıdır ve her bir terim için biaslama yapmak için fazladan bir eleman daha($\\theta_0$) kullanırız (bias elemanının feature değeri($\\mathbf{x_0}$)  1'dir).\n* 'z', feature matrisi 'x' ile ağırlık vektörü 'theta'nın çarpımından hesaplanır.  $z = \\mathbf{x}.\\mathbf{\\theta}$\n    * $\\mathbf{x}$'in boyutları: (m, n+1) \n    * $\\mathbf{\\theta}$'nın boyutları: (n+1, 1)\n    * $\\mathbf{z}$'nin boyutları: (m, 1)\n* Tahmin(h), her elemana sigmoid fonksiyonu uygulanarak elde edilmiştir: \n$h(z) = sigmoid(z)$. 'h', (m,1) boyutlarındadır.\n* Maliyet fonksiyonu($J$), 'y' ve 'log(h)' vektörlerinin nokta çarpımı alınarak hesaplanır. Hem 'y' hem de 'h' sütun vektörleri (m,1) olduğundan, vektörü sola aktarın, böylece bir satır vektörünün sütun vektörüyle matris çarpımı nokta çarpımını gerçekleştirir.\n\n$$J = \\frac{-1}{m} \\times \\left(\\mathbf{y}^T \\cdot log(\\mathbf{h}) + \\mathbf{(1-y)}^T \\cdot log(\\mathbf{1-h}) \\right)$$\n\n* Tetanın güncellenmesi de vektörleştirilmiştir. $\\mathbf{x}$'in boyutları (m, n+1) olduğundan ve hem $\\mathbf{h}$ hem de $\\mathbf{y}$ (m, 1) boyutlarında olduğundan, matris çarpımını gerçekleştirmek için $\\mathbf{x}$'in transpozesini alıp sola yerleştirmemiz gerekir, bu da ihtiyacımız olan (n+1, 1) cevabını verir:\n$$\\mathbf{\\theta} = \\mathbf{\\theta} - \\frac{\\alpha}{m} \\times \\left( \\mathbf{x}^T \\cdot \\left( \\mathbf{h-y} \\right) \\right)$$","metadata":{}},{"cell_type":"code","source":"def gradientDescent(x, y, theta, alpha, num_iters):\n    '''\n    Input:\n        x: feature matrisi, (m,n+1) boyutlarinda\n        y: inputtaki x'e karsilik gelen etiketler, (m,1) boyutlarinda\n        theta: agirlik vektoru, (n+1,1) boyutlarinda\n        alpha: ogrenme orani\n        num_iters: modeli kac defa egitmek istiyorsak degeri bu parametreye veririz \n    Output:\n        J: maliyet\n        theta: son agirlik vektoru\n    '''\n\n    m = x.shape[0]\n    \n    for i in range(0, num_iters):\n        \n        # x ve theta'nin nokta carpimi\n        z = np.dot(x,theta)\n        \n        # z'nin sigmoidi\n        h = sigmoid(z)\n        \n        # maliyet fonksiyonunu hesaplayalim\n        J = -1./m * (np.dot(y.transpose(), np.log(h)) + np.dot((1-y).transpose(),np.log(1-h)))\n\n        # agirliklari guncelleyelim\n        theta = theta - (alpha/m) * np.dot(x.transpose(),(h-y))\n        \n    J = float(J)\n    return J, theta","metadata":{"execution":{"iopub.status.busy":"2024-07-23T11:33:33.808096Z","iopub.execute_input":"2024-07-23T11:33:33.808589Z","iopub.status.idle":"2024-07-23T11:33:33.820912Z","shell.execute_reply.started":"2024-07-23T11:33:33.808542Z","shell.execute_reply":"2024-07-23T11:33:33.819708Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"## Özellik çıkarımı\n* Verilen tweet listesinden iki özellik çıkarımı yapacağız: \n    * Tweetteki pozitif kelime sayısı\n    * Tweetteki negatif kelime sayısı\n* Daha sonra bu iki özellikle lojistik regresyonumuzu güncelleyeceğiz\n\n### extract_features fonksiyonu\n* Bu fonksiyon tek bir tweeti işler\n* İlk olarak `process_tweet()` fonksiyonuyla tweeti temizleriz\n* Temizlenen tweetteki her kelime için döngüye gireriz \n    * Her kelime için 'freqs' kütüphanesinde pozitif cümlelerde ve negatif cümlelerde kaçar defa geçtiği bilgisini saklarız.","metadata":{}},{"cell_type":"code","source":"def extract_features(tweet, freqs):\n\n    word_l = process_tweet(tweet)\n    \n    # pozitif frekans, negatif frekans ve bias olmak uzere her kelimenin uc degeri mevcut(1x3)\n    x = np.zeros((1, 3)) \n    \n    #bias terimini 1 olarak ayarliyoruz\n    x[0,0] = 1 \n    \n    #dizideki tum kelimeler icin donguye giriyoruz\n    for word in word_l:\n        \n        # etiket pozitifse kelimenin pozitif frekans degerini bir arttiriyoruz\n        x[0,1] += freqs.get((word, 1.0),0)\n        \n        # etiket negatifse kelimenin negatif frekans degerini bir arttiriyoruz\n        x[0,2] += freqs.get((word, 0.0),0)\n        \n    assert(x.shape == (1, 3))\n    return x","metadata":{"execution":{"iopub.status.busy":"2024-07-23T11:33:33.822533Z","iopub.execute_input":"2024-07-23T11:33:33.822956Z","iopub.status.idle":"2024-07-23T11:33:33.834706Z","shell.execute_reply.started":"2024-07-23T11:33:33.822918Z","shell.execute_reply":"2024-07-23T11:33:33.833675Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"## Modelin eğitilmesi\n\nModeli eğitmek için:\n* Tüm eğitimler sonucu elde ettiğiniz değerleri 'X' matrisine geçirin.\n* `gradientDescent` fonksiyonunu çağırın.","metadata":{}},{"cell_type":"code","source":"# featurelari 'X' matrisine gecirelim\nX = np.zeros((len(train_x), 3))\nfor i in range(len(train_x)):\n    X[i, :]= extract_features(train_x[i], freqs)\n\n# X'e karsilik gelen etiketleri Y'ye gecirelim\nY = train_y\n\n# Gradient descent uygulayalim\nJ, theta = gradientDescent(X, Y, np.zeros((3, 1)), 1e-9, 1500)\nprint(f\"Egitim sonrasi maliyet {J:.8f}.\")\nprint(f\"Ortaya cikan agirlik vektoru {[round(t, 8) for t in np.squeeze(theta)]}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-23T11:33:33.836129Z","iopub.execute_input":"2024-07-23T11:33:33.836505Z","iopub.status.idle":"2024-07-23T11:33:40.288092Z","shell.execute_reply.started":"2024-07-23T11:33:33.836471Z","shell.execute_reply":"2024-07-23T11:33:40.286928Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"Egitim sonrasi maliyet 0.24216529.\nOrtaya cikan agirlik vektoru [7e-08, 0.0005239, -0.00055517]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Lojistik regresyonu test edelim\n\nModelin eğitildiği veri setinde olmayan bir tweeti lojistik regresyona sokalım.\n\n#### `predict_tweet` fonksiyonu\nTweetin olumlu mu olumsuz mu olduğunu tahmin ettirelim.\n\n* Tweeti işleyip kelimelerinin frekans değerlerini saptayalım.\n* Eğitimi gerçekleşmiş modele tweeti sokalım ve değerini tahmin edelim\n\n$$y_{pred} = sigmoid(\\mathbf{x} \\cdot \\theta)$$","metadata":{}},{"cell_type":"code","source":"def predict_tweet(tweet, freqs, theta):\n    \n    # tweetin özellik çıkarımını yapıp x'e aktaralım\n    x = extract_features(tweet,freqs)\n    \n    # x ve theta ile tahmini yapalım\n    y_pred =sigmoid(np.dot(x,theta))\n    \n    return y_pred","metadata":{"execution":{"iopub.status.busy":"2024-07-23T11:33:40.293017Z","iopub.execute_input":"2024-07-23T11:33:40.293475Z","iopub.status.idle":"2024-07-23T11:33:40.300530Z","shell.execute_reply.started":"2024-07-23T11:33:40.293433Z","shell.execute_reply":"2024-07-23T11:33:40.299259Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"# predict_tweet'i test edelim\n# Olumlu tweetlerin 0.5-1 araliginda, olumsuz tweetlerin 0-0.5 araliginda olmasini bekliyoruz\n\ntweet1 = 'I am happy'\ntweet2 = 'I am bad'\nprint( '%s -> %f' % (tweet1, predict_tweet(tweet1, freqs, theta)))\nprint( '%s -> %f' % (tweet1, predict_tweet(tweet2, freqs, theta)))","metadata":{"execution":{"iopub.status.busy":"2024-07-23T11:33:40.302738Z","iopub.execute_input":"2024-07-23T11:33:40.303172Z","iopub.status.idle":"2024-07-23T11:33:40.326245Z","shell.execute_reply.started":"2024-07-23T11:33:40.303115Z","shell.execute_reply":"2024-07-23T11:33:40.324642Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"I am happy -> 0.518580\nI am happy -> 0.494339\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Test verileriyle performansı kontrol edelim\n\n#### `test_logistic_regression` fonksiyonu\n* Test verileri ve eğitilen modelinizin ağırlıkları göz önüne alındığında, lojistik regresyon modelinizin doğruluğunu hesaplayın.\n* Test kümesindeki her tweetin değeri `predict_tweet()` fonksiyonuyla tahmin edilir\n* Tahmin > 0,5 ise modelin sınıflandırmasını 1 olarak, aksi takdirde 0 olarak ayarlayalım.\n* Bir tahmin, tweetingerçek değerine (test_y) eşit olduğunda doğrudur. Eşit oldukları tüm durumları toplayıp ve 'm'ye bölelim.","metadata":{}},{"cell_type":"code","source":"def test_logistic_regression(test_x, test_y, freqs, theta):\n    \"\"\"\n    Input: \n        test_x: tweet listesi\n        test_y: tweetin gercek degeri, boyutlar(m, 1)\n        theta: agirlik vektoru, boyutlar(3, 1)\n    Output: \n        accuracy: dogru siniflandirilan tweet sayisi / tum tweet sayisi\n    \"\"\"\n    \n    # tahminleri saklayacagimiz liste\n    y_hat = []\n    \n    for tweet in test_x:\n        y_pred = predict_tweet(tweet, freqs, theta)\n        \n        if y_pred > 0.5:\n            y_hat.append(1)\n        else:\n            y_hat.append(0)\n\n    accuracy = (y_hat==np.squeeze(test_y)).sum()/len(test_x)\n\n    return accuracy","metadata":{"execution":{"iopub.status.busy":"2024-07-23T11:33:40.327925Z","iopub.execute_input":"2024-07-23T11:33:40.328326Z","iopub.status.idle":"2024-07-23T11:33:40.338556Z","shell.execute_reply.started":"2024-07-23T11:33:40.328287Z","shell.execute_reply":"2024-07-23T11:33:40.337302Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"tmp_accuracy = test_logistic_regression(test_x, test_y, freqs, theta)\nprint(f\"Modelin dogrulugu = {tmp_accuracy:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-23T11:33:40.340438Z","iopub.execute_input":"2024-07-23T11:33:40.340825Z","iopub.status.idle":"2024-07-23T11:33:41.781028Z","shell.execute_reply.started":"2024-07-23T11:33:40.340778Z","shell.execute_reply":"2024-07-23T11:33:41.779957Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"Modelin dogrulugu = 0.9950\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Hata Analizi\nYanlış sınıflandırdığımız tweetleri inceleyelim.","metadata":{}},{"cell_type":"code","source":"print('Yanlis Siniflandirilan Tweet')\nfor x,y in zip(test_x,test_y):\n    y_hat = predict_tweet(x, freqs, theta)\n\n    if np.abs(y - (y_hat > 0.5)) > 0:\n        print('Tweet:', x)\n        print('Islenmis hali:', process_tweet(x))\n        print('%d\\t%0.8f\\t%s' % (y, y_hat, ' '.join(process_tweet(x)).encode('ascii', 'ignore')))","metadata":{"execution":{"iopub.status.busy":"2024-07-23T11:33:41.782824Z","iopub.execute_input":"2024-07-23T11:33:41.783326Z","iopub.status.idle":"2024-07-23T11:33:43.264062Z","shell.execute_reply.started":"2024-07-23T11:33:41.783285Z","shell.execute_reply":"2024-07-23T11:33:43.262935Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"Yanlis Siniflandirilan Tweet\nTweet: @jaredNOTsubway @iluvmariah @Bravotv Then that truly is a LATERAL move! Now, we all know the Queen Bee is UPWARD BOUND : ) #MovingOnUp\nIslenmis hali: ['truli', 'later', 'move', 'know', 'queen', 'bee', 'upward', 'bound', 'movingonup']\n1\t0.49996890\tb'truli later move know queen bee upward bound movingonup'\nTweet: @MarkBreech Not sure it would be good thing 4 my bottom daring 2 say 2 Miss B but Im gonna be so stubborn on mouth soaping ! #NotHavingit :p\nIslenmis hali: ['sure', 'would', 'good', 'thing', '4', 'bottom', 'dare', '2', 'say', '2', 'miss', 'b', 'im', 'gonna', 'stubborn', 'mouth', 'soap', 'nothavingit', ':p']\n1\t0.48622857\tb'sure would good thing 4 bottom dare 2 say 2 miss b im gonna stubborn mouth soap nothavingit :p'\nTweet: I'm playing Brain Dots : ) #BrainDots\nhttp://t.co/UGQzOx0huu\nIslenmis hali: [\"i'm\", 'play', 'brain', 'dot', 'braindot']\n1\t0.48370665\tb\"i'm play brain dot braindot\"\nTweet: I'm playing Brain Dots : ) #BrainDots http://t.co/aOKldo3GMj http://t.co/xWCM9qyRG5\nIslenmis hali: [\"i'm\", 'play', 'brain', 'dot', 'braindot']\n1\t0.48370665\tb\"i'm play brain dot braindot\"\nTweet: I'm playing Brain Dots : ) #BrainDots http://t.co/R2JBO8iNww http://t.co/ow5BBwdEMY\nIslenmis hali: [\"i'm\", 'play', 'brain', 'dot', 'braindot']\n1\t0.48370665\tb\"i'm play brain dot braindot\"\nTweet: off to the park to get some sunlight : )\nIslenmis hali: ['park', 'get', 'sunlight']\n1\t0.49578765\tb'park get sunlight'\nTweet: @msarosh Uff Itna Miss karhy thy ap :p\nIslenmis hali: ['uff', 'itna', 'miss', 'karhi', 'thi', 'ap', ':p']\n1\t0.48199810\tb'uff itna miss karhi thi ap :p'\nTweet: @phenomyoutube u probs had more fun with david than me : (\nIslenmis hali: ['u', 'prob', 'fun', 'david']\n0\t0.50020353\tb'u prob fun david'\nTweet: pats jay : (\nIslenmis hali: ['pat', 'jay']\n0\t0.50039294\tb'pat jay'\nTweet: my beloved grandmother : ( https://t.co/wt4oXq5xCf\nIslenmis hali: ['belov', 'grandmoth']\n0\t0.50000002\tb'belov grandmoth'\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Kendi tweetlerinizi deneyin","metadata":{}},{"cell_type":"code","source":"your_tweet = 'This is a ridiculously bright movie. The plot was terrible and I was sad until the ending!'\ny_hat = predict_tweet(your_tweet, freqs, theta)\nif y_hat > 0.5:\n    print('Pozitif cumle')\nelse: \n    print('Negatif cumle')","metadata":{"execution":{"iopub.status.busy":"2024-07-23T11:33:43.265850Z","iopub.execute_input":"2024-07-23T11:33:43.266417Z","iopub.status.idle":"2024-07-23T11:33:43.274328Z","shell.execute_reply.started":"2024-07-23T11:33:43.266377Z","shell.execute_reply":"2024-07-23T11:33:43.273335Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"Negatif cumle\n","output_type":"stream"}]}]}